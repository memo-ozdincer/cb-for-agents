[
  {
    "sites": [
      "shopping_admin"
    ],
    "task_id": 0,
    "require_login": true,
    "storage_state": "./.auth/shopping_admin_state.json",
    "start_url": "__SHOPPING_ADMIN__",
    "geolocation": null,
    "intent_template": "What is the top-{{n}} best-selling product in {{year}}",
    "instantiation_dict": {
      "n": 1,
      "year": 2022
    },
    "intent": "What is the top-1 best-selling product in 2022",
    "require_reset": false,
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "exact_match": "Quest Lumaflex\u2122 Band"
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "Quest Lumaflex\u2122 Band"
    },
    "intent_template_id": 279
  },
  {
    "sites": [
      "shopping_admin"
    ],
    "task_id": 1,
    "require_login": true,
    "storage_state": "./.auth/shopping_admin_state.json",
    "start_url": "__SHOPPING_ADMIN__",
    "geolocation": null,
    "intent_template": "What is the top-{{n}} best-selling brand in {{period}}",
    "instantiation_dict": {
      "n": 1,
      "period": "Quarter 1 2022"
    },
    "intent": "What is the top-1 best-selling brand in Quarter 1 2022",
    "require_reset": false,
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "exact_match": "Sprite"
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "Sprite"
    },
    "intent_template_id": 279
  },
  {
    "sites": [
      "shopping_admin"
    ],
    "task_id": 2,
    "require_login": true,
    "storage_state": "./.auth/shopping_admin_state.json",
    "start_url": "__SHOPPING_ADMIN__",
    "geolocation": null,
    "intent_template": "What is the top-{{n}} best-selling product type in {{period}}",
    "instantiation_dict": {
      "n": 1,
      "period": "Quarter 1 2022"
    },
    "intent": "What is the top-1 best-selling product type in Quarter 1 2022",
    "require_reset": false,
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "exact_match": "Yoga ball"
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "Yoga ball"
    },
    "intent_template_id": 279
  },
  {
    "sites": [
      "shopping_admin"
    ],
    "task_id": 3,
    "require_login": true,
    "storage_state": "./.auth/shopping_admin_state.json",
    "start_url": "__SHOPPING_ADMIN__",
    "geolocation": null,
    "intent_template": "What are the top-{{n}} best-selling product in {{year}}",
    "instantiation_dict": {
      "n": 2,
      "year": 2022
    },
    "intent": "What are the top-2 best-selling product in 2022",
    "require_reset": false,
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "Quest Lumaflex\u2122 Band",
          "Sprite Stasis Ball 65 cm"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "Quest Lumaflex\u2122 Band, Sprite Stasis Ball 65 cm"
    },
    "intent_template_id": 279
  },
  {
    "sites": [
      "shopping_admin"
    ],
    "task_id": 4,
    "require_login": true,
    "storage_state": "./.auth/shopping_admin_state.json",
    "start_url": "__SHOPPING_ADMIN__",
    "geolocation": null,
    "intent_template": "What are the top-{{n}} best-selling product in {{period}}",
    "instantiation_dict": {
      "n": 3,
      "period": "Jan 2023"
    },
    "intent": "What are the top-3 best-selling product in Jan 2023",
    "require_reset": false,
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "Impulse Duffle",
          "Overnight Duffle",
          "Hawkeye Yoga Short-32-Blue"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "Impulse Duffle, Overnight Duffle, Hawkeye Yoga Short-32-Blue"
    },
    "intent_template_id": 279
  },
  {
    "sites": [
      "shopping_admin"
    ],
    "task_id": 5,
    "require_login": true,
    "storage_state": "./.auth/shopping_admin_state.json",
    "start_url": "__SHOPPING_ADMIN__",
    "geolocation": null,
    "intent_template": "What is the top-{{n}} best-selling product type in {{period}}",
    "instantiation_dict": {
      "n": 1,
      "period": "Jan 2023"
    },
    "intent": "What is the top-1 best-selling product type in Jan 2023",
    "require_reset": false,
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "exact_match": "Duffle"
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "Duffle"
    },
    "intent_template_id": 279
  },
  {
    "sites": [
      "shopping_admin"
    ],
    "task_id": 6,
    "require_login": true,
    "storage_state": "./.auth/shopping_admin_state.json",
    "start_url": "__SHOPPING_ADMIN__",
    "geolocation": null,
    "intent_template": "What are the top-{{n}} best-selling product in {{year}}",
    "instantiation_dict": {
      "n": 5,
      "year": 2023
    },
    "intent": "What are the top-5 best-selling product in 2023",
    "require_reset": false,
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "Sprite Yoga Strap 6 foot",
          "Overnight Duffle",
          "Ida Workout Parachute Pant-29-Purple",
          "Hawkeye Yoga Short-32-Blue",
          "Sprite Stasis Ball 65 cm"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "Sprite Yoga Strap 6 foot, Overnight Duffle, Ida Workout Parachute Pant-29-Purple, Hawkeye Yoga Short-32-Blue, Sprite Stasis Ball 65 cm"
    },
    "intent_template_id": 279
  },
  {
    "sites": [
      "map"
    ],
    "task_id": 7,
    "require_login": true,
    "storage_state": null,
    "start_url": "__MAP__",
    "geolocation": null,
    "intent_template": "Tell me the full address of all {{airport_type}} that are within a driving distance of {{radius}} to {{start}}",
    "instantiation_dict": {
      "airport_type": "international airports",
      "start": "Carnegie Mellon University",
      "radius": "50 km"
    },
    "intent": "Tell me the full address of all international airports that are within a driving distance of 50 km to Carnegie Mellon University",
    "require_reset": false,
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "exact_match": "Pittsburgh International Airport, Southern Beltway, Findlay Township, Allegheny County, 15231, United States"
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "Pittsburgh International Airport People Movers, Airport Boulevard, Findlay Township, Allegheny County, Pennsylvania, 15231, United States"
    },
    "intent_template_id": 79
  },
  {
    "sites": [
      "map"
    ],
    "task_id": 8,
    "require_login": true,
    "storage_state": null,
    "start_url": "__MAP__",
    "geolocation": null,
    "intent_template": "Tell me the full address of all {{airport_type}} that are within a driving distance of {{radius}} to {{start}}",
    "instantiation_dict": {
      "airport_type": "international airports",
      "start": "Carnegie Mellon University",
      "radius": "5 km"
    },
    "intent": "Tell me the full address of all international airports that are within a driving distance of 5 km to Carnegie Mellon University",
    "require_reset": false,
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "fuzzy_match": [
          "There is no airport within 5 km of Carnegie Mellon University"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "There is no airport within 5 km of Carnegie Mellon University"
    },
    "intent_template_id": 79
  },
  {
    "sites": [
      "map"
    ],
    "task_id": 9,
    "require_login": true,
    "storage_state": null,
    "start_url": "__MAP__",
    "geolocation": null,
    "intent_template": "Tell me the full address of all {{airport_type}} that are within a driving distance of {{radius}} to {{start}}",
    "instantiation_dict": {
      "airport_type": "international airports",
      "start": "Carnegie Art Museum",
      "radius": "30 km"
    },
    "intent": "Tell me the full address of all international airports that are within a driving distance of 30 km to Carnegie Art Museum",
    "require_reset": false,
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "Pittsburgh International Airport, Southern Beltway, Findlay Township, Allegheny County, 15231, United States"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "Pittsburgh International Airport People Movers, Airport Boulevard, Findlay Township, Allegheny County, Pennsylvania, 15231, United States"
    },
    "intent_template_id": 79
  },
  {
    "sites": [
      "map"
    ],
    "task_id": 10,
    "require_login": true,
    "storage_state": null,
    "start_url": "__MAP__",
    "geolocation": null,
    "intent_template": "Tell me the full address of all {{airport_type}} that are within a driving distance of {{radius}} to {{start}}",
    "instantiation_dict": {
      "airport_type": "US international airports",
      "start": "Niagara Falls",
      "radius": "60 km"
    },
    "intent": "Tell me the full address of all US international airports that are within a driving distance of 60 km to Niagara Falls",
    "require_reset": false,
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "Niagara Falls International Airport, 2035, Niagara Falls Boulevard, City of Niagara Falls, Town of Wheatfield, Niagara County, New York, 14304, United States",
          "Buffalo-Niagara International Airport, Holtz Drive, Town of Cheektowaga, Erie County, New York, 14225, United States"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "Niagara Falls International Airport, 2035, Niagara Falls Boulevard, City of Niagara Falls, Town of Wheatfield, Niagara County, New York, 14304, United States Buffalo-Niagara International Airport, South Youngs Road, Town of Cheektowaga, Erie County, New York, 14221, United States"
    },
    "intent_template_id": 79
  },
  {
    "sites": [
      "shopping_admin"
    ],
    "task_id": 11,
    "require_login": true,
    "storage_state": "./.auth/shopping_admin_state.json",
    "start_url": "__SHOPPING_ADMIN__",
    "geolocation": null,
    "intent_template": "Tell me the the number of reviews that our store received by far that mention term \"{{term}}\"",
    "instantiation_dict": {
      "term": "disappointed"
    },
    "intent": "Tell me the the number of reviews that our store received by far that mention term \"disappointed\"",
    "require_reset": false,
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "6"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "6"
    },
    "intent_template_id": 288
  },
  {
    "sites": [
      "shopping_admin"
    ],
    "task_id": 12,
    "require_login": true,
    "storage_state": "./.auth/shopping_admin_state.json",
    "start_url": "__SHOPPING_ADMIN__",
    "geolocation": null,
    "intent_template": "Tell me the the number of reviews that our store received by far that mention term \"{{term}}\"",
    "instantiation_dict": {
      "term": "satisfied"
    },
    "intent": "Tell me the the number of reviews that our store received by far that mention term \"satisfied\"",
    "require_reset": false,
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "2"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "2"
    },
    "intent_template_id": 288
  },
  {
    "sites": [
      "shopping_admin"
    ],
    "task_id": 13,
    "require_login": true,
    "storage_state": "./.auth/shopping_admin_state.json",
    "start_url": "__SHOPPING_ADMIN__",
    "geolocation": null,
    "intent_template": "Tell me the the number of reviews that our store received by far that mention term \"{{term}}\"",
    "instantiation_dict": {
      "term": "decent"
    },
    "intent": "Tell me the the number of reviews that our store received by far that mention term \"decent\"",
    "require_reset": false,
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "2"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "2"
    },
    "intent_template_id": 288
  },
  {
    "sites": [
      "shopping_admin"
    ],
    "task_id": 14,
    "require_login": true,
    "storage_state": "./.auth/shopping_admin_state.json",
    "start_url": "__SHOPPING_ADMIN__",
    "geolocation": null,
    "intent_template": "Tell me the the number of reviews that our store received by far that mention term \"{{term}}\"",
    "instantiation_dict": {
      "term": "not useful"
    },
    "intent": "Tell me the the number of reviews that our store received by far that mention term \"not useful\"",
    "require_reset": false,
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "0"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "0"
    },
    "intent_template_id": 288
  },
  {
    "sites": [
      "shopping_admin"
    ],
    "task_id": 15,
    "require_login": true,
    "storage_state": "./.auth/shopping_admin_state.json",
    "start_url": "__SHOPPING_ADMIN__",
    "geolocation": null,
    "intent_template": "Tell me the the number of reviews that our store received by far that mention term \"{{term}}\"",
    "instantiation_dict": {
      "term": "best"
    },
    "intent": "Tell me the the number of reviews that our store received by far that mention term \"best\"",
    "require_reset": false,
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "2"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "2"
    },
    "intent_template_id": 288
  },
  {
    "sites": [
      "map"
    ],
    "task_id": 16,
    "require_login": true,
    "storage_state": null,
    "start_url": "__MAP__",
    "geolocation": null,
    "intent_template": "Compare the time for walking and driving route from {{start}} to {{end}}",
    "instantiation_dict": {
      "start": "5000 Fifth Avenue, Pittsburgh",
      "end": "UPMC family health center"
    },
    "intent": "Compare the time for walking and driving route from 5000 Fifth Avenue, Pittsburgh to UPMC family health center",
    "require_reset": false,
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "fuzzy_match": [
          "driving: 2min",
          "walking: 16min"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "Driving: 2min. Walking: 16min."
    },
    "intent_template_id": 73
  },
  {
    "sites": [
      "map"
    ],
    "task_id": 17,
    "require_login": true,
    "storage_state": null,
    "start_url": "__MAP__",
    "geolocation": null,
    "intent_template": "Compare the time for walking and driving route from {{start}} to {{end}}",
    "instantiation_dict": {
      "start": "AMC Waterfront",
      "end": "Carnegie Mellon University"
    },
    "intent": "Compare the time for walking and driving route from AMC Waterfront to Carnegie Mellon University",
    "require_reset": false,
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "fuzzy_match": [
          "driving: 13min",
          "walking: 1h 35min"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "driving: 13min, walking: 1h 35min."
    },
    "intent_template_id": 73
  },
  {
    "sites": [
      "map"
    ],
    "task_id": 18,
    "require_login": true,
    "storage_state": null,
    "start_url": "__MAP__",
    "geolocation": null,
    "intent_template": "Compare the time for walking and driving route from {{start}} to {{end}}",
    "instantiation_dict": {
      "start": "AMC Waterfront",
      "end": "Univ of Pittsburgh"
    },
    "intent": "Compare the time for walking and driving route from AMC Waterfront to Univ of Pittsburgh",
    "require_reset": false,
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "fuzzy_match": [
          "driving: 15min",
          "walking: 1h 47min"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "driving: 15min, walking: 1h 47min."
    },
    "intent_template_id": 73
  },
  {
    "sites": [
      "map"
    ],
    "task_id": 19,
    "require_login": true,
    "storage_state": null,
    "start_url": "__MAP__",
    "geolocation": null,
    "intent_template": "Compare the time for walking and driving route from {{start}} to {{end}}",
    "instantiation_dict": {
      "start": "Carnegie Science Center",
      "end": "Carnegie Mellon University"
    },
    "intent": "Compare the time for walking and driving route from Carnegie Science Center to Carnegie Mellon University",
    "require_reset": false,
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "fuzzy_match": [
          "driving: 12min",
          "walking: 1h 44min."
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "driving: 12min, walking: 1h 44min."
    },
    "intent_template_id": 73
  },
  {
    "sites": [
      "map"
    ],
    "task_id": 20,
    "require_login": true,
    "storage_state": null,
    "start_url": "__MAP__",
    "geolocation": null,
    "intent_template": "Compare the difference in time for walking and driving route from {{start}} to {{end}}",
    "instantiation_dict": {
      "start": "Randyland",
      "end": "Carnegie Mellon University"
    },
    "intent": "Compare the difference in time for walking and driving route from Randyland to Carnegie Mellon University",
    "require_reset": false,
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "fuzzy_match": [
          "driving: 13min",
          "walking: 1h 45min"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "driving: 13min, walking: 1h 45min."
    },
    "intent_template_id": 73
  },
  {
    "sites": [
      "shopping"
    ],
    "task_id": 21,
    "require_login": true,
    "storage_state": "./.auth/shopping_state.json",
    "start_url": "__SHOPPING__/6s-wireless-headphones-over-ear-noise-canceling-hi-fi-bass-foldable-stereo-wireless-kid-headsets-earbuds-with-built-in-mic-micro-sd-tf-fm-for-iphone-samsung-ipad-pc-black-gold.html",
    "geolocation": null,
    "intent_template": "List out reviewers, if exist, who mention about {{description}}",
    "instantiation_dict": {
      "description": "ear cups being small"
    },
    "intent": "List out reviewers, if exist, who mention about ear cups being small",
    "require_reset": false,
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "Joseph Brzezinski",
          "Catso",
          "Dibbins",
          "Anglebert Dinkherhump",
          "Michelle Davis"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "Joseph Brzezinski, Catso, Dibbins, Anglebert Dinkherhump, Michelle Davis"
    },
    "intent_template_id": 222
  },
  {
    "sites": [
      "shopping"
    ],
    "task_id": 22,
    "require_login": true,
    "storage_state": "./.auth/shopping_state.json",
    "start_url": "__SHOPPING__/fujifilm-finepix-z200fd-10mp-digital-camera-with-5x-optical-dual-image-stabilized-zoom-black.html",
    "geolocation": null,
    "intent_template": "List out reviewers, if exist, who mention about {{description}}",
    "instantiation_dict": {
      "description": "under water photo"
    },
    "intent": "List out reviewers, if exist, who mention about under water photo",
    "require_reset": false,
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "fuzzy_match": "N/A"
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "There is no review about under water photo",
      "reference_answer_raw_annotation": "N/A"
    },
    "intent_template_id": 222
  },
  {
    "sites": [
      "shopping"
    ],
    "task_id": 23,
    "require_login": true,
    "storage_state": "./.auth/shopping_state.json",
    "start_url": "__SHOPPING__/3-pack-samsung-galaxy-s6-screen-protector-nearpow-tempered-glass-screen-protector-with-9h-hardness-crystal-clear-easy-bubble-free-installation-scratch-resist.html",
    "geolocation": null,
    "intent_template": "List out reviewers, if exist, who mention about {{description}}",
    "instantiation_dict": {
      "description": "good fingerprint resistant"
    },
    "intent": "List out reviewers, if exist, who mention about good fingerprint resistant",
    "require_reset": false,
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "Rachel",
          "T. Gannon"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "Rachel, T. Gannon, "
    },
    "intent_template_id": 222
  },
  {
    "sites": [
      "shopping"
    ],
    "task_id": 24,
    "require_login": true,
    "storage_state": "./.auth/shopping_state.json",
    "start_url": "__SHOPPING__/haflinger-men-s-wool-felt-open-back-slippers-beige-550-peat-us-7.html",
    "geolocation": null,
    "intent_template": "List out reviewers, if exist, who mention about {{description}}",
    "instantiation_dict": {
      "description": "price being unfair"
    },
    "intent": "List out reviewers, if exist, who mention about price being unfair",
    "require_reset": false,
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "fuzzy_match": "N/A"
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "There is no reivew about price being unfair",
      "reference_answer_raw_annotation": "N/A"
    },
    "intent_template_id": 222
  },
  {
    "sites": [
      "shopping"
    ],
    "task_id": 25,
    "require_login": true,
    "storage_state": "./.auth/shopping_state.json",
    "start_url": "__SHOPPING__/epson-workforce-wf-3620-wifi-direct-all-in-one-color-inkjet-printer-copier-scanner-amazon-dash-replenishment-ready.html",
    "geolocation": null,
    "intent_template": "List out reviewers, if exist, who mention about {{description}}",
    "instantiation_dict": {
      "description": "average print quality"
    },
    "intent": "List out reviewers, if exist, who mention about average print quality",
    "require_reset": false,
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "Goldfish",
          "Roxanne Brandon Coffey"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "GoldfishGoldfish, Roxanne Brandon Coffey"
    },
    "intent_template_id": 222
  },
  {
    "sites": [
      "shopping"
    ],
    "task_id": 26,
    "require_login": true,
    "storage_state": "./.auth/shopping_state.json",
    "start_url": "__SHOPPING__/epson-workforce-wf-3620-wifi-direct-all-in-one-color-inkjet-printer-copier-scanner-amazon-dash-replenishment-ready.html",
    "geolocation": null,
    "intent_template": "List out reviewers, if exist, who mention about {{description}}",
    "instantiation_dict": {
      "description": "complain of the customer service"
    },
    "intent": "List out reviewers, if exist, who mention about complain of the customer service",
    "require_reset": false,
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "Bob in Vegas",
          "RemyR"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "Bob in Vegas, RemyRRemyR"
    },
    "intent_template_id": 222
  },
  {
    "sites": [
      "reddit"
    ],
    "task_id": 27,
    "require_login": true,
    "storage_state": "./.auth/reddit_state.json",
    "start_url": "__REDDIT__",
    "geolocation": null,
    "intent_template": "Tell me the count of comments that have received more downvotes than upvotes for the user who made the latest post on the {{forum}} forum.",
    "instantiation_dict": {
      "forum": "Showerthoughts"
    },
    "intent": "Tell me the count of comments that have received more downvotes than upvotes for the user who made the latest post on the Showerthoughts forum.",
    "require_reset": false,
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "0"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "0"
    },
    "intent_template_id": 33
  },
  {
    "sites": [
      "reddit"
    ],
    "task_id": 28,
    "require_login": true,
    "storage_state": "./.auth/reddit_state.json",
    "start_url": "__REDDIT__",
    "geolocation": null,
    "intent_template": "Tell me the count of comments that have received more downvotes than upvotes for the user who made the latest post on the {{forum}} forum.",
    "instantiation_dict": {
      "forum": "Worcester"
    },
    "intent": "Tell me the count of comments that have received more downvotes than upvotes for the user who made the latest post on the Worcester forum.",
    "require_reset": false,
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "0"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "0"
    },
    "intent_template_id": 33
  },
  {
    "sites": [
      "reddit"
    ],
    "task_id": 29,
    "require_login": true,
    "storage_state": "./.auth/reddit_state.json",
    "start_url": "__REDDIT__",
    "geolocation": null,
    "intent_template": "Tell me the count of comments that have received more downvotes than upvotes for the user who made the latest post on the {{forum}} forum.",
    "instantiation_dict": {
      "forum": "DIY"
    },
    "intent": "Tell me the count of comments that have received more downvotes than upvotes for the user who made the latest post on the DIY forum.",
    "require_reset": false,
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "1"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "1"
    },
    "intent_template_id": 33
  },
  {
    "sites": [
      "reddit"
    ],
    "task_id": 30,
    "require_login": true,
    "storage_state": "./.auth/reddit_state.json",
    "start_url": "__REDDIT__",
    "geolocation": null,
    "intent_template": "Tell me the count of comments that have received more downvotes than upvotes for the user who made the latest post on the {{forum}} forum.",
    "instantiation_dict": {
      "forum": "space"
    },
    "intent": "Tell me the count of comments that have received more downvotes than upvotes for the user who made the latest post on the space forum.",
    "require_reset": false,
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "0"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "0"
    },
    "intent_template_id": 33
  },
  {
    "sites": [
      "reddit"
    ],
    "task_id": 31,
    "require_login": true,
    "storage_state": "./.auth/reddit_state.json",
    "start_url": "__REDDIT__",
    "geolocation": null,
    "intent_template": "Tell me the count of comments that have received more downvotes than upvotes for the user who made the latest post on the {{forum}} forum.",
    "instantiation_dict": {
      "forum": "photoshopbattles"
    },
    "intent": "Tell me the count of comments that have received more downvotes than upvotes for the user who made the latest post on the photoshopbattles forum.",
    "require_reset": false,
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "0"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "0"
    },
    "intent_template_id": 33
  },
  {
    "sites": [
      "map"
    ],
    "task_id": 32,
    "require_login": true,
    "storage_state": null,
    "start_url": "__MAP__",
    "geolocation": null,
    "intent_template": "I will arrive {{place}} soon. Provide the name of a {{target1}} in the vicinity, if available. Then, tell me the {{information}} to {{target2}} from the hotel.",
    "instantiation_dict": {
      "place": "Pittsburgh Airport",
      "information": "the walking distance",
      "target1": "Hilton hotel",
      "target2": "the nearest supermarket own by a local company"
    },
    "intent": "I will arrive Pittsburgh Airport soon. Provide the name of a Hilton hotel in the vicinity, if available. Then, tell me the the walking distance to the nearest supermarket own by a local company from the hotel.",
    "require_reset": false,
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "DoubleTree by Hilton Hotel Pittsburgh Airport",
          "2.0km"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "DoubleTree by Hilton Hotel Pittsburgh Airport Distance: 2.0km"
    },
    "intent_template_id": 78
  },
  {
    "sites": [
      "map"
    ],
    "task_id": 33,
    "require_login": true,
    "storage_state": null,
    "start_url": "__MAP__",
    "geolocation": null,
    "intent_template": "I will arrive {{place}} soon. Provide the name of a {{target1}} in the vicinity, if available. Then, tell me the {{information}} to {{target2}} from the hotel.",
    "instantiation_dict": {
      "place": "Pittsburgh Airport",
      "target1": "Hilton hotel",
      "information": "the shortest walking distance",
      "target2": "a supermarket"
    },
    "intent": "I will arrive Pittsburgh Airport soon. Provide the name of a Hilton hotel in the vicinity, if available. Then, tell me the the shortest walking distance to a supermarket from the hotel.",
    "require_reset": false,
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "DoubleTree by Hilton Hotel Pittsburgh Airport",
          "1.4km"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "DoubleTree by Hilton Hotel Pittsburgh Airport Distance: 1.4km"
    },
    "intent_template_id": 78
  },
  {
    "sites": [
      "map"
    ],
    "task_id": 34,
    "require_login": true,
    "storage_state": null,
    "start_url": "__MAP__",
    "geolocation": null,
    "intent_template": "I will arrive {{place}} soon. Provide the name of a {{target1}} in the vicinity, if available. Then, tell me the {{information}} to {{target2}} from the hotel.",
    "instantiation_dict": {
      "place": "Pittsburgh Airport",
      "target1": "Hyatt hotel",
      "information": "the shortest walking time",
      "target2": "a supermarket"
    },
    "intent": "I will arrive Pittsburgh Airport soon. Provide the name of a Hyatt hotel in the vicinity, if available. Then, tell me the the shortest walking time to a supermarket from the hotel.",
    "require_reset": false,
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "Hyatt Regency Pittsburgh International Airport"
        ],
        "fuzzy_match": [
          "Time: 3h 30min"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "Hyatt Regency Pittsburgh International Airport\n3:30"
    },
    "intent_template_id": 78
  },
  {
    "sites": [
      "map"
    ],
    "task_id": 35,
    "require_login": true,
    "storage_state": null,
    "start_url": "__MAP__",
    "geolocation": null,
    "intent_template": "I will arrive {{place}} soon. Provide the name of a {{target1}} in the vicinity, if available. Then, tell me the {{information}} to {{target2}} from the hotel.",
    "instantiation_dict": {
      "place": "Pittsburgh Airport",
      "target1": "Hyatt hotel",
      "information": "the minimal driving time",
      "target2": "a supermarket"
    },
    "intent": "I will arrive Pittsburgh Airport soon. Provide the name of a Hyatt hotel in the vicinity, if available. Then, tell me the the minimal driving time to a supermarket from the hotel.",
    "require_reset": false,
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "Hyatt Regency Pittsburgh International Airport"
        ],
        "fuzzy_match": [
          "Time: 15min"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "Hyatt Regency Pittsburgh International Airport Time: 15min"
    },
    "intent_template_id": 78
  },
  {
    "sites": [
      "map"
    ],
    "task_id": 36,
    "require_login": true,
    "storage_state": null,
    "start_url": "__MAP__",
    "geolocation": null,
    "intent_template": "Check if the {{place}} in pittsburgh can be reached in one hour by car from {{location}}",
    "instantiation_dict": {
      "place": "social security administration",
      "location": "Carnegie Mellon University"
    },
    "intent": "Check if the social security administration in pittsburgh can be reached in one hour by car from Carnegie Mellon University",
    "require_reset": false,
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "Yes"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "Yes"
    },
    "intent_template_id": 77
  },
  {
    "sites": [
      "map"
    ],
    "task_id": 37,
    "require_login": true,
    "storage_state": null,
    "start_url": "__MAP__",
    "geolocation": null,
    "intent_template": "Check if the {{place}} in pittsburgh can be reached in one hour by car from {{location}}",
    "instantiation_dict": {
      "place": "police station",
      "location": "gates building at CMU"
    },
    "intent": "Check if the police station in pittsburgh can be reached in one hour by car from gates building at CMU",
    "require_reset": false,
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "Yes"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "Yes"
    },
    "intent_template_id": 77
  },
  {
    "sites": [
      "map"
    ],
    "task_id": 38,
    "require_login": true,
    "storage_state": null,
    "start_url": "__MAP__",
    "geolocation": null,
    "intent_template": "Check if the {{place}} in pittsburgh can be reached in one hour by car from {{location}}",
    "instantiation_dict": {
      "place": "duquesne university",
      "location": "pittsburgh airport"
    },
    "intent": "Check if the duquesne university in pittsburgh can be reached in one hour by car from pittsburgh airport",
    "require_reset": false,
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "Yes"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "Yes"
    },
    "intent_template_id": 77
  },
  {
    "sites": [
      "map"
    ],
    "task_id": 39,
    "require_login": true,
    "storage_state": null,
    "start_url": "__MAP__",
    "geolocation": null,
    "intent_template": "Check if the {{place}} in pittsburgh can be reached in one hour by car from {{location}}",
    "instantiation_dict": {
      "place": "walmart",
      "location": "5600 fifth avenue"
    },
    "intent": "Check if the walmart in pittsburgh can be reached in one hour by car from 5600 fifth avenue",
    "require_reset": false,
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "Yes"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "Yes"
    },
    "intent_template_id": 77
  },
  {
    "sites": [
      "map"
    ],
    "task_id": 40,
    "require_login": true,
    "storage_state": null,
    "start_url": "__MAP__",
    "geolocation": null,
    "intent_template": "Check if the {{place}} in pittsburgh can be reached in one hour by car from {{location}}",
    "instantiation_dict": {
      "place": "amc theatre",
      "location": "hobart street"
    },
    "intent": "Check if the amc theatre in pittsburgh can be reached in one hour by car from hobart street",
    "require_reset": false,
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "Yes"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "Yes"
    },
    "intent_template_id": 77
  },
  {
    "sites": [
      "shopping_admin"
    ],
    "task_id": 41,
    "require_login": true,
    "storage_state": "./.auth/shopping_admin_state.json",
    "start_url": "__SHOPPING_ADMIN__",
    "geolocation": null,
    "intent_template": "List the top {{n}} search terms in my store",
    "instantiation_dict": {
      "n": "1"
    },
    "intent": "List the top 1 search terms in my store",
    "require_reset": false,
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "exact_match": "hollister"
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "hollister"
    },
    "intent_template_id": 285
  },
  {
    "sites": [
      "shopping_admin"
    ],
    "task_id": 42,
    "require_login": true,
    "storage_state": "./.auth/shopping_admin_state.json",
    "start_url": "__SHOPPING_ADMIN__",
    "geolocation": null,
    "intent_template": "List the top {{n}} search terms in my store",
    "instantiation_dict": {
      "n": "2"
    },
    "intent": "List the top 2 search terms in my store",
    "require_reset": false,
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "hollister",
          "Joust Bag"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "hollister, Joust Bag"
    },
    "intent_template_id": 285
  },
  {
    "sites": [
      "shopping_admin"
    ],
    "task_id": 43,
    "require_login": true,
    "storage_state": "./.auth/shopping_admin_state.json",
    "start_url": "__SHOPPING_ADMIN__",
    "geolocation": null,
    "intent_template": "List the top {{n}} search terms in my store",
    "instantiation_dict": {
      "n": "3"
    },
    "intent": "List the top 3 search terms in my store",
    "require_reset": false,
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "hollister",
          "Joust Bag",
          "Antonia Racer Tank"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "hollister, Joust Bag, Antonia Race Tank"
    },
    "intent_template_id": 285
  },
  {
    "sites": [
      "gitlab"
    ],
    "task_id": 44,
    "require_login": true,
    "storage_state": "./.auth/gitlab_state.json",
    "start_url": "__GITLAB__",
    "geolocation": null,
    "intent_template": "Check out my todos",
    "instantiation_dict": {},
    "intent": "Check out my todos",
    "require_reset": false,
    "eval": {
      "eval_types": [
        "url_match"
      ],
      "reference_answers": null,
      "reference_url": "__GITLAB__/dashboard/todos",
      "program_html": [],
      "url_note": "GOLD in PRED"
    },
    "intent_template_id": 303
  },
  {
    "sites": [
      "gitlab"
    ],
    "task_id": 45,
    "require_login": true,
    "storage_state": "./.auth/gitlab_state.json",
    "start_url": "__GITLAB__/a11yproject/a11yproject.com",
    "geolocation": null,
    "intent_template": "Check out the most recent open issues",
    "instantiation_dict": {},
    "intent": "Check out the most recent open issues",
    "require_reset": false,
    "eval": {
      "eval_types": [
        "url_match"
      ],
      "reference_answers": null,
      "reference_url": "__GITLAB__/a11yproject/a11yproject.com/-/issues/?sort=created_asc&state=opened",
      "program_html": [],
      "url_note": "GOLD in PRED"
    },
    "intent_template_id": 300
  },
  {
    "sites": [
      "gitlab"
    ],
    "task_id": 46,
    "require_login": true,
    "storage_state": "./.auth/gitlab_state.json",
    "start_url": "__GITLAB__/primer/design",
    "geolocation": null,
    "intent_template": "Check out the most recent open issues",
    "instantiation_dict": {},
    "intent": "Check out the most recent open issues",
    "require_reset": false,
    "eval": {
      "eval_types": [
        "url_match"
      ],
      "reference_answers": null,
      "reference_url": "__GITLAB__/primer/design/-/issues/?sort=created_date&state=opened",
      "program_html": [],
      "url_note": "GOLD in PRED"
    },
    "intent_template_id": 300
  },
  {
    "sites": [
      "shopping"
    ],
    "task_id": 47,
    "require_login": true,
    "storage_state": "./.auth/shopping_state.json",
    "start_url": "__SHOPPING__",
    "geolocation": null,
    "intent_template": "Today is 6/12/2023. Tell me how many fulfilled orders I have {{period}}, and the total amount of money I spent.",
    "instantiation_dict": {
      "period": "over the past month"
    },
    "intent": "Today is 6/12/2023. Tell me how many fulfilled orders I have over the past month, and the total amount of money I spent.",
    "require_reset": false,
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "fuzzy_match": [
          "0 order",
          "$0 total spend"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "0 order, $0 total spend"
    },
    "intent_template_id": 197
  },
  {
    "sites": [
      "shopping"
    ],
    "task_id": 48,
    "require_login": true,
    "storage_state": "./.auth/shopping_state.json",
    "start_url": "__SHOPPING__",
    "geolocation": null,
    "intent_template": "Today is 6/12/2023. Tell me how many fulfilled orders I have {{period}}, and the total amount of money I spent.",
    "instantiation_dict": {
      "period": "over the past three days"
    },
    "intent": "Today is 6/12/2023. Tell me how many fulfilled orders I have over the past three days, and the total amount of money I spent.",
    "require_reset": false,
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "fuzzy_match": [
          "0 order",
          "$0 total spend"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "0 order, $0 total spend"
    },
    "intent_template_id": 197
  },
  {
    "sites": [
      "shopping"
    ],
    "task_id": 49,
    "require_login": true,
    "storage_state": "./.auth/shopping_state.json",
    "start_url": "__SHOPPING__",
    "geolocation": null,
    "intent_template": "Today is 6/12/2023. Tell me how many fulfilled orders I have {{period}}, and the total amount of money I spent.",
    "instantiation_dict": {
      "period": "over the past four month"
    },
    "intent": "Today is 6/12/2023. Tell me how many fulfilled orders I have over the past four month, and the total amount of money I spent.",
    "require_reset": false,
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "fuzzy_match": [
          "3 orders",
          "$845.49 total spend"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "3 orders, $845.49 total spend"
    },
    "intent_template_id": 197
  },
  {
    "sites": [
      "shopping"
    ],
    "task_id": 50,
    "require_login": true,
    "storage_state": "./.auth/shopping_state.json",
    "start_url": "__SHOPPING__",
    "geolocation": null,
    "intent_template": "Today is 6/12/2023. Tell me how many fulfilled orders I have {{period}}, and the total amount of money I spent.",
    "instantiation_dict": {
      "period": "over the past year"
    },
    "intent": "Today is 6/12/2023. Tell me how many fulfilled orders I have over the past year, and the total amount of money I spent.",
    "require_reset": false,
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "fuzzy_match": [
          "24 orders",
          "$6560.69 total spend"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "24 orders, $6560.69 total spend"
    },
    "intent_template_id": 197
  },
  {
    "sites": [
      "shopping"
    ],
    "task_id": 51,
    "require_login": true,
    "storage_state": "./.auth/shopping_state.json",
    "start_url": "__SHOPPING__",
    "geolocation": null,
    "intent_template": "Today is 6/12/2023. Tell me how many fulfilled orders I have {{period}}, and the total amount of money I spent.",
    "instantiation_dict": {
      "period": "over the past six month"
    },
    "intent": "Today is 6/12/2023. Tell me how many fulfilled orders I have over the past six month, and the total amount of money I spent.",
    "require_reset": false,
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "fuzzy_match": [
          "12 orders",
          "$1603.69 total spend"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "12 orders, $1603.69 total spend"
    },
    "intent_template_id": 197
  },
  {
    "sites": [
      "map"
    ],
    "task_id": 52,
    "require_login": true,
    "storage_state": null,
    "start_url": "__MAP__",
    "geolocation": null,
    "intent_template": "How long does it take to walk from {{start}} to {{end}}?",
    "instantiation_dict": {
      "start": "Carnegie Mellon University",
      "end": "starbucks on Craig Street"
    },
    "intent": "How long does it take to walk from Carnegie Mellon University to starbucks on Craig Street?",
    "require_reset": false,
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "fuzzy_match": [
          "7 min"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "7 min"
    },
    "intent_template_id": 68
  },
  {
    "sites": [
      "map"
    ],
    "task_id": 53,
    "require_login": true,
    "storage_state": null,
    "start_url": "__MAP__",
    "geolocation": null,
    "intent_template": "How long does it take to walk from {{start}} to {{end}}?",
    "instantiation_dict": {
      "start": "Univ of Pittsburgh",
      "end": "starbucks on Craig Street"
    },
    "intent": "How long does it take to walk from Univ of Pittsburgh to starbucks on Craig Street?",
    "require_reset": false,
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "fuzzy_match": [
          "18 min"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "18 min"
    },
    "intent_template_id": 68
  },
  {
    "sites": [
      "map"
    ],
    "task_id": 54,
    "require_login": true,
    "storage_state": null,
    "start_url": "__MAP__",
    "geolocation": null,
    "intent_template": "How long does it take to walk from {{start}} to {{end}}?",
    "instantiation_dict": {
      "start": "Carnegie Mellon University",
      "end": "Univ of Pittsburgh"
    },
    "intent": "How long does it take to walk from Carnegie Mellon University to Univ of Pittsburgh?",
    "require_reset": false,
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "fuzzy_match": [
          "25 min"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "25 min"
    },
    "intent_template_id": 68
  },
  {
    "sites": [
      "map"
    ],
    "task_id": 55,
    "require_login": true,
    "storage_state": null,
    "start_url": "__MAP__",
    "geolocation": null,
    "intent_template": "How long does it take to walk from {{start}} to {{end}}?",
    "instantiation_dict": {
      "start": "the starbuck near CMU",
      "end": "Chatham university"
    },
    "intent": "How long does it take to walk from the starbuck near CMU to Chatham university?",
    "require_reset": false,
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "fuzzy_match": [
          "30 min"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "30 min"
    },
    "intent_template_id": 68
  },
  {
    "sites": [
      "map"
    ],
    "task_id": 56,
    "require_login": true,
    "storage_state": null,
    "start_url": "__MAP__",
    "geolocation": null,
    "intent_template": "How long does it take to walk from {{start}} to {{end}}?",
    "instantiation_dict": {
      "start": "Carnegie Museum of Art",
      "end": "a library at CMU"
    },
    "intent": "How long does it take to walk from Carnegie Museum of Art to a library at CMU?",
    "require_reset": false,
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "fuzzy_match": [
          "11 min"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "11 min"
    },
    "intent_template_id": 68
  },
  {
    "sites": [
      "map"
    ],
    "task_id": 57,
    "require_login": true,
    "storage_state": null,
    "start_url": "__MAP__",
    "geolocation": null,
    "intent_template": "Tell me the closest {{place1}}(s) to {{place2}}",
    "instantiation_dict": {
      "place1": "restaurant",
      "place2": "university center at Carnegie Mellon University"
    },
    "intent": "Tell me the closest restaurant(s) to university center at Carnegie Mellon University",
    "require_reset": false,
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "El Gallo de Oro",
          "Back Bar Grill",
          "Grano",
          "Beefsteak",
          "Nourish",
          "Schatz Dining Room",
          "Au Bon Pain"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "El Gallo de Oro, Back Bar Grill, Grano, Beefsteak, Nourish, Schatz Dining Room, Au Bon Pain"
    },
    "intent_template_id": 69
  },
  {
    "sites": [
      "map"
    ],
    "task_id": 58,
    "require_login": true,
    "storage_state": null,
    "start_url": "__MAP__",
    "geolocation": null,
    "intent_template": "Tell me the closest {{place1}}(s) to {{place2}}",
    "instantiation_dict": {
      "place1": "cafe",
      "place2": "CMU Hunt library"
    },
    "intent": "Tell me the closest cafe(s) to CMU Hunt library",
    "require_reset": false,
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "De Fer Coffee & Tea"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "De Fer Coffee & Tea"
    },
    "intent_template_id": 69
  },
  {
    "sites": [
      "map"
    ],
    "task_id": 59,
    "require_login": true,
    "storage_state": null,
    "start_url": "__MAP__",
    "geolocation": null,
    "intent_template": "Tell me the closest {{place1}}(s) to {{place2}}",
    "instantiation_dict": {
      "place1": "restaurant",
      "place2": "CMU Hunt library"
    },
    "intent": "Tell me the closest restaurant(s) to CMU Hunt library",
    "require_reset": false,
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "The exchange"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "The exchange"
    },
    "intent_template_id": 69
  },
  {
    "sites": [
      "map"
    ],
    "task_id": 60,
    "require_login": true,
    "storage_state": null,
    "start_url": "__MAP__",
    "geolocation": null,
    "intent_template": "Tell me the closest {{place1}}(s) to {{place2}}",
    "instantiation_dict": {
      "place1": "restaurant",
      "place2": "CMU Posner Hall"
    },
    "intent": "Tell me the closest restaurant(s) to CMU Posner Hall",
    "require_reset": false,
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "The exchange"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "The exchange"
    },
    "intent_template_id": 69
  },
  {
    "sites": [
      "map"
    ],
    "task_id": 61,
    "require_login": true,
    "storage_state": null,
    "start_url": "__MAP__",
    "geolocation": null,
    "intent_template": "Tell me the closest {{place1}}(s) to {{place2}}",
    "instantiation_dict": {
      "place1": "restaurant",
      "place2": "CMU Sorrells Library"
    },
    "intent": "Tell me the closest restaurant(s) to CMU Sorrells Library",
    "require_reset": false,
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "La Prima Espresso"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "La Prima Espresso"
    },
    "intent_template_id": 69
  },
  {
    "sites": [
      "shopping_admin"
    ],
    "task_id": 62,
    "require_login": true,
    "storage_state": "./.auth/shopping_admin_state.json",
    "start_url": "__SHOPPING_ADMIN__",
    "geolocation": null,
    "intent_template": "Which customer has completed the {{quantifier}} number of orders in the entire history?",
    "instantiation_dict": {
      "quantifier": "most"
    },
    "intent": "Which customer has completed the most number of orders in the entire history?",
    "require_reset": false,
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "Jane Smith"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "Jane Smith"
    },
    "intent_template_id": 276
  },
  {
    "sites": [
      "shopping_admin"
    ],
    "task_id": 63,
    "require_login": true,
    "storage_state": "./.auth/shopping_admin_state.json",
    "start_url": "__SHOPPING_ADMIN__",
    "geolocation": null,
    "intent_template": "Which customer(s) has completed the {{quantifier}} number of orders in the entire history?",
    "instantiation_dict": {
      "quantifier": "second most"
    },
    "intent": "Which customer(s) has completed the second most number of orders in the entire history?",
    "require_reset": false,
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "Adam Garcia",
          "Michael Nguyen",
          "Sarah Miller"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "Adam Garcia, Michael Nguyen, Sarah Miller"
    },
    "intent_template_id": 276
  },
  {
    "sites": [
      "shopping_admin"
    ],
    "task_id": 64,
    "require_login": true,
    "storage_state": "./.auth/shopping_admin_state.json",
    "start_url": "__SHOPPING_ADMIN__",
    "geolocation": null,
    "intent_template": "Which customer has placed {{number}} orders in the entire history?",
    "instantiation_dict": {
      "number": "2"
    },
    "intent": "Which customer has placed 2 orders in the entire history?",
    "require_reset": false,
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "Lisa Kim",
          "Lisa Green",
          "Julia Williams",
          "Brian Smith",
          "Alexander Thomas"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "Lisa Kim, Lisa Green, Julia Williams, Brian Smith, Alexander Thomas"
    },
    "intent_template_id": 276
  },
  {
    "sites": [
      "shopping_admin"
    ],
    "task_id": 65,
    "require_login": true,
    "storage_state": "./.auth/shopping_admin_state.json",
    "start_url": "__SHOPPING_ADMIN__",
    "geolocation": null,
    "intent_template": "Which customer has completed the {{quantifier}} number of orders in the entire history?",
    "instantiation_dict": {
      "quantifier": "fifth most"
    },
    "intent": "Which customer has completed the fifth most number of orders in the entire history?",
    "require_reset": false,
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "Jane Doe"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "Jane Doe"
    },
    "intent_template_id": 276
  },
  {
    "sites": [
      "reddit"
    ],
    "task_id": 66,
    "require_login": true,
    "storage_state": "./.auth/reddit_state.json",
    "start_url": "__REDDIT__",
    "geolocation": null,
    "intent_template": "Among the top {{number}} post in \"{{subreddit}}\" forum, {{description}}",
    "instantiation_dict": {
      "number": 10,
      "subreddit": "books",
      "description": "show me the post URLs that recommand a single book"
    },
    "intent": "Among the top 10 post in \"books\" forum, show me the post URLs that recommand a single book",
    "require_reset": false,
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "http://www.reddit.com/f/books/59396/apple-books-has-a-free-audiobook-of-a-christmas-carol",
          "http://www.reddit.com/f/books/17445/i-just-finished-reading-the-hobbit-to-my-6-year-old-daughter"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "__REDDIT__/f/books/59396/apple-books-has-a-free-audiobook-of-a-christmas-carol, __REDDIT__/f/books/17445/i-just-finished-reading-the-hobbit-to-my-6-year-old-daughter"
    },
    "intent_template_id": 17
  },
  {
    "sites": [
      "reddit"
    ],
    "task_id": 67,
    "require_login": true,
    "storage_state": "./.auth/reddit_state.json",
    "start_url": "__REDDIT__",
    "geolocation": null,
    "intent_template": "Among the top {{number}} post in \"{{subreddit}}\" forum, {{description}}",
    "instantiation_dict": {
      "number": 10,
      "subreddit": "books",
      "description": "show me the book names from posts that recommand a single book"
    },
    "intent": "Among the top 10 post in \"books\" forum, show me the book names from posts that recommand a single book",
    "require_reset": false,
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "A Christmas Carol",
          "The Hobbit"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "A Christmas Carol, The Hobbit"
    },
    "intent_template_id": 17
  },
  {
    "sites": [
      "reddit"
    ],
    "task_id": 68,
    "require_login": true,
    "storage_state": "./.auth/reddit_state.json",
    "start_url": "__REDDIT__",
    "geolocation": null,
    "intent_template": "Among the top {{number}} post in \"{{subreddit}}\" forum, {{description}}",
    "instantiation_dict": {
      "number": 10,
      "subreddit": "books",
      "description": "show me the author name and the book name from posts that recommand a single book"
    },
    "intent": "Among the top 10 post in \"books\" forum, show me the author name and the book name from posts that recommand a single book",
    "require_reset": false,
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "A Christmas Carol",
          "Levar Burton",
          "The Hobbit",
          "J. R. R. Tolkien"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "A Christmas Carol by Levar Burton: , The Hobbit by J. R. R. Tolkien"
    },
    "intent_template_id": 17
  },
  {
    "sites": [
      "reddit"
    ],
    "task_id": 69,
    "require_login": true,
    "storage_state": "./.auth/reddit_state.json",
    "start_url": "__REDDIT__",
    "geolocation": null,
    "intent_template": "Among the top {{number}} post in \"{{subreddit}}\" forum, {{description}}",
    "instantiation_dict": {
      "number": 10,
      "subreddit": "books",
      "description": "is there any post talks about supporting local book stores? If so, tell me the organizations involved"
    },
    "intent": "Among the top 10 post in \"books\" forum, is there any post talks about supporting local book stores? If so, tell me the organizations involved",
    "require_reset": false,
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "bookshop.org"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "bookshop.org"
    },
    "intent_template_id": 17
  },
  {
    "sites": [
      "map"
    ],
    "task_id": 70,
    "require_login": true,
    "storage_state": null,
    "start_url": "__MAP__",
    "geolocation": null,
    "intent_template": "What is the zip code of {{place}}?",
    "instantiation_dict": {
      "place": "Carnegie Mellon University"
    },
    "intent": "What is the zip code of Carnegie Mellon University?",
    "require_reset": false,
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "exact_match": "15213"
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "15213"
    },
    "intent_template_id": 70
  },
  {
    "sites": [
      "map"
    ],
    "task_id": 71,
    "require_login": true,
    "storage_state": null,
    "start_url": "__MAP__",
    "geolocation": null,
    "intent_template": "What is the zip code of {{place}}?",
    "instantiation_dict": {
      "place": "Chatham University"
    },
    "intent": "What is the zip code of Chatham University?",
    "require_reset": false,
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "exact_match": "15232"
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "15232"
    },
    "intent_template_id": 70
  },
  {
    "sites": [
      "map"
    ],
    "task_id": 72,
    "require_login": true,
    "storage_state": null,
    "start_url": "__MAP__",
    "geolocation": null,
    "intent_template": "What is the zip code of {{place}}?",
    "instantiation_dict": {
      "place": "Yale University"
    },
    "intent": "What is the zip code of Yale University?",
    "require_reset": false,
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "exact_match": "06516"
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "06516"
    },
    "intent_template_id": 70
  },
  {
    "sites": [
      "map"
    ],
    "task_id": 73,
    "require_login": true,
    "storage_state": null,
    "start_url": "__MAP__",
    "geolocation": null,
    "intent_template": "What is the zip code of {{place}}?",
    "instantiation_dict": {
      "place": "Columbia University"
    },
    "intent": "What is the zip code of Columbia University?",
    "require_reset": false,
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "exact_match": "10027"
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "10027"
    },
    "intent_template_id": 70
  },
  {
    "sites": [
      "map"
    ],
    "task_id": 74,
    "require_login": true,
    "storage_state": null,
    "start_url": "__MAP__",
    "geolocation": null,
    "intent_template": "Given the following locations, {{place_list}}, what would be the optimal route to travel through them all in order to minimize total travel time? Please note the journey begins at the first place listed.",
    "instantiation_dict": {
      "place_list": [
        "Carnegie Mellon University",
        "apple store shadyside",
        "starbucks on craig street"
      ]
    },
    "intent": "Given the following locations, ['Carnegie Mellon University', 'apple store shadyside', 'starbucks on craig street'], what would be the optimal route to travel through them all in order to minimize total travel time? Please note the journey begins at the first place listed.",
    "require_reset": false,
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "fuzzy_match": [
          "The order is Carnegie Mellon University, starbucks on forbes ave, apple store shadyside"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "Carnegie Mellon University, starbucks on forbes ave, apple store shadyside"
    },
    "intent_template_id": 65
  },
  {
    "sites": [
      "map"
    ],
    "task_id": 75,
    "require_login": true,
    "storage_state": null,
    "start_url": "__MAP__",
    "geolocation": null,
    "intent_template": "Given the following locations, {{place_list}}, what would be the optimal route to travel through them all in order to minimize total travel time? Please note the journey begins at the first place listed.",
    "instantiation_dict": {
      "place_list": [
        "Massachusetts Institute of Technology",
        "Harvard University",
        "Boston Logan International Airport"
      ]
    },
    "intent": "Given the following locations, ['Massachusetts Institute of Technology', 'Harvard University', 'Boston Logan International Airport'], what would be the optimal route to travel through them all in order to minimize total travel time? Please note the journey begins at the first place listed.",
    "require_reset": false,
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "fuzzy_match": [
          "The order is Massachusetts Institute of Technology, Harvard University, Boston Logan International Airport"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "Massachusetts Institute of Technology, Harvard University, Boston Logan International Airport"
    },
    "intent_template_id": 65
  },
  {
    "sites": [
      "map"
    ],
    "task_id": 76,
    "require_login": true,
    "storage_state": null,
    "start_url": "__MAP__",
    "geolocation": null,
    "intent_template": "Given the following locations, {{place_list}}, what would be the optimal route to travel through them all in order to minimize total travel time? Please note the journey begins at the first place listed.",
    "instantiation_dict": {
      "place_list": [
        "Princeton University",
        "Yale University",
        "Harvard University"
      ]
    },
    "intent": "Given the following locations, ['Princeton University', 'Yale University', 'Harvard University'], what would be the optimal route to travel through them all in order to minimize total travel time? Please note the journey begins at the first place listed.",
    "require_reset": false,
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "The order is Princeton University, Yale University, Harvard University"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "Princeton University, Yale University, Harvard University"
    },
    "intent_template_id": 65
  },
  {
    "sites": [
      "shopping_admin"
    ],
    "task_id": 77,
    "require_login": true,
    "storage_state": "./.auth/shopping_admin_state.json",
    "start_url": "__SHOPPING_ADMIN__",
    "geolocation": null,
    "intent_template": "What is the total count of {{status}} reviews amongst all the reviews?",
    "instantiation_dict": {
      "status": "Pending"
    },
    "intent": "What is the total count of Pending reviews amongst all the reviews?",
    "require_reset": false,
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "5"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "5"
    },
    "intent_template_id": 277
  },
  {
    "sites": [
      "shopping_admin"
    ],
    "task_id": 78,
    "require_login": true,
    "storage_state": "./.auth/shopping_admin_state.json",
    "start_url": "__SHOPPING_ADMIN__",
    "geolocation": null,
    "intent_template": "What is the total count of {{status}} reviews amongst all the reviews?",
    "instantiation_dict": {
      "status": "Approved"
    },
    "intent": "What is the total count of Approved reviews amongst all the reviews?",
    "require_reset": false,
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "346"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "346"
    },
    "intent_template_id": 277
  },
  {
    "sites": [
      "shopping_admin"
    ],
    "task_id": 79,
    "require_login": true,
    "storage_state": "./.auth/shopping_admin_state.json",
    "start_url": "__SHOPPING_ADMIN__",
    "geolocation": null,
    "intent_template": "What is the total count of {{status}} reviews amongst all the reviews?",
    "instantiation_dict": {
      "status": "Not Approved"
    },
    "intent": "What is the total count of Not Approved reviews amongst all the reviews?",
    "require_reset": false,
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "0"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "0"
    },
    "intent_template_id": 277
  },
  {
    "sites": [
      "map"
    ],
    "task_id": 80,
    "require_login": true,
    "storage_state": null,
    "start_url": "__MAP__",
    "geolocation": null,
    "intent_template": "What is the duration required to first walk from {{place_A}} to {{place_B}}, and then drive to {{place_C}}?",
    "instantiation_dict": {
      "place_A": "Carnegie Mellon University",
      "place_B": "Starbucks on Craig Street",
      "place_C": "Pittsburgh International Airport"
    },
    "intent": "What is the duration required to first walk from Carnegie Mellon University to Starbucks on Craig Street, and then drive to Pittsburgh International Airport?",
    "require_reset": false,
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "fuzzy_match": [
          "38 min"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "38 min"
    },
    "intent_template_id": 72
  },
  {
    "sites": [
      "map"
    ],
    "task_id": 81,
    "require_login": true,
    "storage_state": null,
    "start_url": "__MAP__",
    "geolocation": null,
    "intent_template": "What is the duration required to first walk from {{place_A}} to {{place_B}}, and then drive to {{place_C}}?",
    "instantiation_dict": {
      "place_A": "Univ of Pittsburgh",
      "place_B": "starbucks on Craig Street",
      "place_C": "Pittsburgh International Airport"
    },
    "intent": "What is the duration required to first walk from Univ of Pittsburgh to starbucks on Craig Street, and then drive to Pittsburgh International Airport?",
    "require_reset": false,
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "fuzzy_match": [
          "49 min"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "49 min"
    },
    "intent_template_id": 72
  },
  {
    "sites": [
      "map"
    ],
    "task_id": 82,
    "require_login": true,
    "storage_state": null,
    "start_url": "__MAP__",
    "geolocation": null,
    "intent_template": "What is the duration required to first walk from {{place_A}} to {{place_B}}, and then drive to {{place_C}}?",
    "instantiation_dict": {
      "place_A": "Massachusetts Institute of Technology",
      "place_B": "Harvard University",
      "place_C": "Boston Logan International Airport"
    },
    "intent": "What is the duration required to first walk from Massachusetts Institute of Technology to Harvard University, and then drive to Boston Logan International Airport?",
    "require_reset": false,
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "fuzzy_match": [
          "63 min"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "63 min"
    },
    "intent_template_id": 72
  },
  {
    "sites": [
      "map"
    ],
    "task_id": 83,
    "require_login": true,
    "storage_state": null,
    "start_url": "__MAP__",
    "geolocation": null,
    "intent_template": "What is the duration required to first walk from {{place_A}} to {{place_B}}, and then drive to {{place_C}}?",
    "instantiation_dict": {
      "place_A": "Carnegie Mellon University",
      "place_B": "apple store shadyside",
      "place_C": "starbucks on craig street"
    },
    "intent": "What is the duration required to first walk from Carnegie Mellon University to apple store shadyside, and then drive to starbucks on craig street?",
    "require_reset": false,
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "fuzzy_match": [
          "22 min"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "22 min"
    },
    "intent_template_id": 72
  },
  {
    "sites": [
      "map"
    ],
    "task_id": 84,
    "require_login": true,
    "storage_state": null,
    "start_url": "__MAP__",
    "geolocation": null,
    "intent_template": "From my stay at {{hotel}}, what's the estimated driving time to reach {{place}}?",
    "instantiation_dict": {
      "hotel": "DoubleTree by Hilton New York Downtown",
      "place": "Keens Steakhouse"
    },
    "intent": "From my stay at DoubleTree by Hilton New York Downtown, what's the estimated driving time to reach Keens Steakhouse?",
    "require_reset": false,
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "fuzzy_match": [
          "14 minutes"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "14 minutes"
    },
    "intent_template_id": 64
  },
  {
    "sites": [
      "map"
    ],
    "task_id": 85,
    "require_login": true,
    "storage_state": null,
    "start_url": "__MAP__",
    "geolocation": null,
    "intent_template": "From my stay at {{hotel}}, what's the estimated driving time to reach {{place}}?",
    "instantiation_dict": {
      "hotel": "La Quinta Inn near the airport",
      "place": "Carnegie Mellon University"
    },
    "intent": "From my stay at La Quinta Inn near the airport, what's the estimated driving time to reach Carnegie Mellon University?",
    "require_reset": false,
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "fuzzy_match": [
          "30 minutes"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "30 minutes"
    },
    "intent_template_id": 64
  },
  {
    "sites": [
      "map"
    ],
    "task_id": 86,
    "require_login": true,
    "storage_state": null,
    "start_url": "__MAP__",
    "geolocation": null,
    "intent_template": "From my stay at {{hotel}}, what's the estimated driving time to reach {{place}}?",
    "instantiation_dict": {
      "hotel": "La Quinta Inn near the airport",
      "place": "Upitt"
    },
    "intent": "From my stay at La Quinta Inn near the airport, what's the estimated driving time to reach Upitt?",
    "require_reset": false,
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "fuzzy_match": [
          "29 minutes"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "29 minutes"
    },
    "intent_template_id": 64
  },
  {
    "sites": [
      "map"
    ],
    "task_id": 87,
    "require_login": true,
    "storage_state": null,
    "start_url": "__MAP__",
    "geolocation": null,
    "intent_template": "From my stay at {{hotel}}, what's the estimated driving time to reach {{place}}?",
    "instantiation_dict": {
      "hotel": "red roof inn",
      "place": "Pittsburgh science museum"
    },
    "intent": "From my stay at red roof inn, what's the estimated driving time to reach Pittsburgh science museum?",
    "require_reset": false,
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "fuzzy_match": [
          "20 minutes"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "20 minutes"
    },
    "intent_template_id": 64
  },
  {
    "sites": [
      "map"
    ],
    "task_id": 88,
    "require_login": true,
    "storage_state": null,
    "start_url": "__MAP__",
    "geolocation": null,
    "intent_template": "From my stay at {{hotel}}, what's the estimated driving time to reach {{place}}?",
    "instantiation_dict": {
      "hotel": "Homewood Suites Southpointe",
      "place": "PPG Paints Arena"
    },
    "intent": "From my stay at Homewood Suites Southpointe, what's the estimated driving time to reach PPG Paints Arena?",
    "require_reset": false,
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "fuzzy_match": [
          "34 minutes"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "34 minutes"
    },
    "intent_template_id": 64
  },
  {
    "sites": [
      "map"
    ],
    "task_id": 89,
    "require_login": true,
    "storage_state": null,
    "start_url": "__MAP__",
    "geolocation": null,
    "intent_template": "Which US states border {{state}}?",
    "instantiation_dict": {
      "state": "Connecticut"
    },
    "intent": "Which US states border Connecticut?",
    "require_reset": false,
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "Rhode Island",
          "Massachusetts",
          "New York"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "Rhode Island, Massachusetts, New York"
    },
    "intent_template_id": 67
  },
  {
    "sites": [
      "map"
    ],
    "task_id": 90,
    "require_login": true,
    "storage_state": null,
    "start_url": "__MAP__",
    "geolocation": null,
    "intent_template": "Which US states border {{state}}?",
    "instantiation_dict": {
      "state": "Pennsylvania"
    },
    "intent": "Which US states border Pennsylvania?",
    "require_reset": false,
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "Ohio",
          "Maryland",
          "New York",
          "New Jersey",
          "Delaware",
          "West Virginia"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "Ohio, Maryland, New York, New Jersey, Delaware, West Virginia"
    },
    "intent_template_id": 67
  },
  {
    "sites": [
      "map"
    ],
    "task_id": 91,
    "require_login": true,
    "storage_state": null,
    "start_url": "__MAP__",
    "geolocation": null,
    "intent_template": "Which US states border {{state}}?",
    "instantiation_dict": {
      "state": "Massachusetts"
    },
    "intent": "Which US states border Massachusetts?",
    "require_reset": false,
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "Rhode Island",
          "Connecticut",
          "New York",
          "New Hampshire",
          "Vermont"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "Rhode Island, Connecticut, New York, New Hampshire, Vermont"
    },
    "intent_template_id": 67
  },
  {
    "sites": [
      "map"
    ],
    "task_id": 92,
    "require_login": true,
    "storage_state": null,
    "start_url": "__MAP__",
    "geolocation": null,
    "intent_template": "Which US states border {{state}}?",
    "instantiation_dict": {
      "state": "Vermont"
    },
    "intent": "Which US states border Vermont?",
    "require_reset": false,
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "New York",
          "New Hampshire",
          "Massachusetts"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "New York, New Hampshire, Massachusetts"
    },
    "intent_template_id": 67
  },
  {
    "sites": [
      "map"
    ],
    "task_id": 93,
    "require_login": true,
    "storage_state": null,
    "start_url": "__MAP__",
    "geolocation": null,
    "intent_template": "Which US states border {{state}}?",
    "instantiation_dict": {
      "state": "New Hampshire"
    },
    "intent": "Which US states border New Hampshire?",
    "require_reset": false,
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "Massachusetts",
          "Vermont",
          "Maine"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "Massachusetts, Vermont, Maine"
    },
    "intent_template_id": 67
  },
  {
    "sites": [
      "shopping_admin"
    ],
    "task_id": 94,
    "require_login": true,
    "storage_state": "./.auth/shopping_admin_state.json",
    "start_url": "__SHOPPING_ADMIN__",
    "geolocation": null,
    "intent_template": "Telll me the grand total of invoice {{id}}.",
    "instantiation_dict": {
      "id": "000000001"
    },
    "intent": "Telll me the grand total of invoice 000000001.",
    "require_reset": false,
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "36.39"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "$36.39"
    },
    "intent_template_id": 274
  },
  {
    "sites": [
      "shopping_admin"
    ],
    "task_id": 95,
    "require_login": true,
    "storage_state": "./.auth/shopping_admin_state.json",
    "start_url": "__SHOPPING_ADMIN__",
    "geolocation": null,
    "intent_template": "Telll me the grand total of invoice {{id}}.",
    "instantiation_dict": {
      "id": "000000002"
    },
    "intent": "Telll me the grand total of invoice 000000002.",
    "require_reset": false,
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "39.64"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "$39.64"
    },
    "intent_template_id": 274
  },
  {
    "sites": [
      "shopping"
    ],
    "task_id": 96,
    "require_login": true,
    "storage_state": "./.auth/shopping_state.json",
    "start_url": "__SHOPPING__",
    "geolocation": null,
    "intent_template": "Tell me the status of my latest order and when will it arrive",
    "instantiation_dict": {},
    "intent": "Tell me the status of my latest order and when will it arrive",
    "require_reset": false,
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "fuzzy_match": [
          "The last order was canceled. It will never arrive."
        ]
      },
      "reference_url": "",
      "program_html": [],
      "reference_answer_raw_annotation": "The last order was canceled. It will never arrive.",
      "string_note": ""
    },
    "intent_template_id": 193
  },
  {
    "sites": [
      "map",
      "wikipedia"
    ],
    "task_id": 97,
    "require_login": true,
    "storage_state": null,
    "start_url": "__MAP__",
    "geolocation": null,
    "intent_template": "Tell me the distance to drive from Carnegie Mellon University to the top computer science school in massachusetts",
    "instantiation_dict": {},
    "intent": "Tell me the distance to drive from Carnegie Mellon University to the top computer science school in massachusetts",
    "require_reset": false,
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "914km"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "914 km"
    },
    "intent_template_id": 120
  },
  {
    "sites": [
      "map"
    ],
    "task_id": 98,
    "require_login": true,
    "storage_state": null,
    "start_url": "__MAP__",
    "geolocation": null,
    "intent_template": "Where is the nearest {{places}} to {{start}}, and what is the walking distance to it?",
    "instantiation_dict": {
      "places": "tea cafe",
      "start": "University of Pittsburgh"
    },
    "intent": "Where is the nearest tea cafe to University of Pittsburgh, and what is the walking distance to it?",
    "require_reset": false,
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "Fuku Tea",
          "3716",
          "Forbes Avenue",
          "Central Oakland",
          "Pittsburgh",
          "653m"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "Fuku Tea, 3716, Forbes Avenue, Oakland, Central Oakland, Pittsburgh, Allegheny County, Pennsylvania, 15213, United States\n653m"
    },
    "intent_template_id": 66
  },
  {
    "sites": [
      "map"
    ],
    "task_id": 99,
    "require_login": true,
    "storage_state": null,
    "start_url": "__MAP__",
    "geolocation": null,
    "intent_template": "Where is the nearest {{places}} to {{start}}, and what is the walking distance to it?",
    "instantiation_dict": {
      "places": "Five Guys",
      "start": "5700 Penn Ave"
    },
    "intent": "Where is the nearest Five Guys to 5700 Penn Ave, and what is the walking distance to it?",
    "require_reset": false,
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "Five Guys",
          "117",
          "South Bouquet Street",
          "North Oakland",
          "Pittsburgh",
          "4.0km"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "Five Guys, 117, South Bouquet Street, Oakland, North Oakland, Pittsburgh, Allegheny County, Pennsylvania, 15213, United States\n4.0km"
    },
    "intent_template_id": 66
  }
]